// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: log.proto

#ifndef PROTOBUF_log_2eproto__INCLUDED
#define PROTOBUF_log_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 2006000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 2006000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

namespace hadoop {
namespace hdfs {

// Internal implementation detail -- do not call these.
void  protobuf_AddDesc_log_2eproto();
void protobuf_AssignDesc_log_2eproto();
void protobuf_ShutdownFile_log_2eproto();

class log;

enum log_FuncType {
  log_FuncType_OPEN = 0,
  log_FuncType_OPEN_RET = 1,
  log_FuncType_CLOSE = 2,
  log_FuncType_CLOSE_RET = 3,
  log_FuncType_READ = 4,
  log_FuncType_READ_RET = 5
};
bool log_FuncType_IsValid(int value);
const log_FuncType log_FuncType_FuncType_MIN = log_FuncType_OPEN;
const log_FuncType log_FuncType_FuncType_MAX = log_FuncType_READ_RET;
const int log_FuncType_FuncType_ARRAYSIZE = log_FuncType_FuncType_MAX + 1;

const ::google::protobuf::EnumDescriptor* log_FuncType_descriptor();
inline const ::std::string& log_FuncType_Name(log_FuncType value) {
  return ::google::protobuf::internal::NameOfEnum(
    log_FuncType_descriptor(), value);
}
inline bool log_FuncType_Parse(
    const ::std::string& name, log_FuncType* value) {
  return ::google::protobuf::internal::ParseNamedEnum<log_FuncType>(
    log_FuncType_descriptor(), name, value);
}
// ===================================================================

class log : public ::google::protobuf::Message {
 public:
  log();
  virtual ~log();

  log(const log& from);

  inline log& operator=(const log& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const log& default_instance();

  void Swap(log* other);

  // implements Message ----------------------------------------------

  log* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const log& from);
  void MergeFrom(const log& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  typedef log_FuncType FuncType;
  static const FuncType OPEN = log_FuncType_OPEN;
  static const FuncType OPEN_RET = log_FuncType_OPEN_RET;
  static const FuncType CLOSE = log_FuncType_CLOSE;
  static const FuncType CLOSE_RET = log_FuncType_CLOSE_RET;
  static const FuncType READ = log_FuncType_READ;
  static const FuncType READ_RET = log_FuncType_READ_RET;
  static inline bool FuncType_IsValid(int value) {
    return log_FuncType_IsValid(value);
  }
  static const FuncType FuncType_MIN =
    log_FuncType_FuncType_MIN;
  static const FuncType FuncType_MAX =
    log_FuncType_FuncType_MAX;
  static const int FuncType_ARRAYSIZE =
    log_FuncType_FuncType_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  FuncType_descriptor() {
    return log_FuncType_descriptor();
  }
  static inline const ::std::string& FuncType_Name(FuncType value) {
    return log_FuncType_Name(value);
  }
  static inline bool FuncType_Parse(const ::std::string& name,
      FuncType* value) {
    return log_FuncType_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // required int32 date = 1;
  inline bool has_date() const;
  inline void clear_date();
  static const int kDateFieldNumber = 1;
  inline ::google::protobuf::int32 date() const;
  inline void set_date(::google::protobuf::int32 value);

  // required int64 time = 2;
  inline bool has_time() const;
  inline void clear_time();
  static const int kTimeFieldNumber = 2;
  inline ::google::protobuf::int64 time() const;
  inline void set_time(::google::protobuf::int64 value);

  // required int64 threadId = 3;
  inline bool has_threadid() const;
  inline void clear_threadid();
  static const int kThreadIdFieldNumber = 3;
  inline ::google::protobuf::int64 threadid() const;
  inline void set_threadid(::google::protobuf::int64 value);

  // required .hadoop.hdfs.log.FuncType type = 4;
  inline bool has_type() const;
  inline void clear_type();
  static const int kTypeFieldNumber = 4;
  inline ::hadoop::hdfs::log_FuncType type() const;
  inline void set_type(::hadoop::hdfs::log_FuncType value);

  // optional string path = 5;
  inline bool has_path() const;
  inline void clear_path();
  static const int kPathFieldNumber = 5;
  inline const ::std::string& path() const;
  inline void set_path(const ::std::string& value);
  inline void set_path(const char* value);
  inline void set_path(const char* value, size_t size);
  inline ::std::string* mutable_path();
  inline ::std::string* release_path();
  inline void set_allocated_path(::std::string* path);

  // repeated int64 argument = 6;
  inline int argument_size() const;
  inline void clear_argument();
  static const int kArgumentFieldNumber = 6;
  inline ::google::protobuf::int64 argument(int index) const;
  inline void set_argument(int index, ::google::protobuf::int64 value);
  inline void add_argument(::google::protobuf::int64 value);
  inline const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
      argument() const;
  inline ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
      mutable_argument();

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.log)
 private:
  inline void set_has_date();
  inline void clear_has_date();
  inline void set_has_time();
  inline void clear_has_time();
  inline void set_has_threadid();
  inline void clear_has_threadid();
  inline void set_has_type();
  inline void clear_has_type();
  inline void set_has_path();
  inline void clear_has_path();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  ::google::protobuf::int64 time_;
  ::google::protobuf::int32 date_;
  int type_;
  ::google::protobuf::int64 threadid_;
  ::std::string* path_;
  ::google::protobuf::RepeatedField< ::google::protobuf::int64 > argument_;
  friend void  protobuf_AddDesc_log_2eproto();
  friend void protobuf_AssignDesc_log_2eproto();
  friend void protobuf_ShutdownFile_log_2eproto();

  void InitAsDefaultInstance();
  static log* default_instance_;
};
// ===================================================================


// ===================================================================

// log

// required int32 date = 1;
inline bool log::has_date() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void log::set_has_date() {
  _has_bits_[0] |= 0x00000001u;
}
inline void log::clear_has_date() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void log::clear_date() {
  date_ = 0;
  clear_has_date();
}
inline ::google::protobuf::int32 log::date() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.log.date)
  return date_;
}
inline void log::set_date(::google::protobuf::int32 value) {
  set_has_date();
  date_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.log.date)
}

// required int64 time = 2;
inline bool log::has_time() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void log::set_has_time() {
  _has_bits_[0] |= 0x00000002u;
}
inline void log::clear_has_time() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void log::clear_time() {
  time_ = GOOGLE_LONGLONG(0);
  clear_has_time();
}
inline ::google::protobuf::int64 log::time() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.log.time)
  return time_;
}
inline void log::set_time(::google::protobuf::int64 value) {
  set_has_time();
  time_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.log.time)
}

// required int64 threadId = 3;
inline bool log::has_threadid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void log::set_has_threadid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void log::clear_has_threadid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void log::clear_threadid() {
  threadid_ = GOOGLE_LONGLONG(0);
  clear_has_threadid();
}
inline ::google::protobuf::int64 log::threadid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.log.threadId)
  return threadid_;
}
inline void log::set_threadid(::google::protobuf::int64 value) {
  set_has_threadid();
  threadid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.log.threadId)
}

// required .hadoop.hdfs.log.FuncType type = 4;
inline bool log::has_type() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void log::set_has_type() {
  _has_bits_[0] |= 0x00000008u;
}
inline void log::clear_has_type() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void log::clear_type() {
  type_ = 0;
  clear_has_type();
}
inline ::hadoop::hdfs::log_FuncType log::type() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.log.type)
  return static_cast< ::hadoop::hdfs::log_FuncType >(type_);
}
inline void log::set_type(::hadoop::hdfs::log_FuncType value) {
  assert(::hadoop::hdfs::log_FuncType_IsValid(value));
  set_has_type();
  type_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.log.type)
}

// optional string path = 5;
inline bool log::has_path() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void log::set_has_path() {
  _has_bits_[0] |= 0x00000010u;
}
inline void log::clear_has_path() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void log::clear_path() {
  if (path_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    path_->clear();
  }
  clear_has_path();
}
inline const ::std::string& log::path() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.log.path)
  return *path_;
}
inline void log::set_path(const ::std::string& value) {
  set_has_path();
  if (path_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    path_ = new ::std::string;
  }
  path_->assign(value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.log.path)
}
inline void log::set_path(const char* value) {
  set_has_path();
  if (path_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    path_ = new ::std::string;
  }
  path_->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.log.path)
}
inline void log::set_path(const char* value, size_t size) {
  set_has_path();
  if (path_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    path_ = new ::std::string;
  }
  path_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.log.path)
}
inline ::std::string* log::mutable_path() {
  set_has_path();
  if (path_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    path_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.log.path)
  return path_;
}
inline ::std::string* log::release_path() {
  clear_has_path();
  if (path_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = path_;
    path_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void log::set_allocated_path(::std::string* path) {
  if (path_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete path_;
  }
  if (path) {
    set_has_path();
    path_ = path;
  } else {
    clear_has_path();
    path_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.log.path)
}

// repeated int64 argument = 6;
inline int log::argument_size() const {
  return argument_.size();
}
inline void log::clear_argument() {
  argument_.Clear();
}
inline ::google::protobuf::int64 log::argument(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.log.argument)
  return argument_.Get(index);
}
inline void log::set_argument(int index, ::google::protobuf::int64 value) {
  argument_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.log.argument)
}
inline void log::add_argument(::google::protobuf::int64 value) {
  argument_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.log.argument)
}
inline const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
log::argument() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.log.argument)
  return argument_;
}
inline ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
log::mutable_argument() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.log.argument)
  return &argument_;
}


// @@protoc_insertion_point(namespace_scope)

}  // namespace hdfs
}  // namespace hadoop

#ifndef SWIG
namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::hadoop::hdfs::log_FuncType> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::log_FuncType>() {
  return ::hadoop::hdfs::log_FuncType_descriptor();
}

}  // namespace google
}  // namespace protobuf
#endif  // SWIG

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_log_2eproto__INCLUDED
